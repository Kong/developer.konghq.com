input/instructions/how-to/set-up-ai-proxy-advanced-with-anthropic/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 401."
input/instructions/how-to/set-up-ai-proxy-with-anthropic/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 401."
input/instructions/how-to/transform-a-client-request-with-ai/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 400."
input/instructions/how-to/transform-a-response-with-ai/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 201, got: 400."
input/instructions/how-to/set-up-ai-proxy-with-openai/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 401."
input/instructions/how-to/set-up-ai-proxy-advanced-with-openai/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 401."
input/instructions/mcp/secure-mcp-traffic/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 401."
input/instructions/how-to/compress-llm-prompts/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code undefined, got: 400."
input/instructions/how-to/protect-sensitive-information-output-with-ai/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 401."
input/instructions/how-to/protect-sensitive-information-with-ai/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 500."
input/instructions/how-to/use-ai-semantic-prompt-guard-plugin/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 400."
input/instructions/ai-gateway/get-started/gateway.yaml: "Expected: request http://localhost:8000/chat to have status code 200, got: 401."
input/instructions/how-to/create-a-complex-ai-chat-history/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 401."
input/instructions/how-to/send-asychronous-llm-requests/gateway.yaml: "Expected: request http://localhost:8000/batches/$BATCH_ID to have status code undefined, got: 401."
input/instructions/how-to/set-up-ai-proxy-advanced-with-ollama/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 502."
input/instructions/how-to/set-up-ai-proxy-with-ollama/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 502."
input/instructions/how-to/use-ai-prompt-template-plugin/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 401."
input/instructions/how-to/use-ai-prompt-guard-plugin/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 401."
input/instructions/how-to/use-azure-ai-content-safety/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 400, got: 500."
input/instructions/how-to/use-ai-semantic-response-guard-plugin/gateway.yaml: "Expected: request http://localhost:8000/anything to have status code 200, got: 400."
---
title: 'Proxy Cache'
name: 'Proxy Cache'

content_type: plugin

publisher: kong-inc
description: 'Cache and serve commonly requested responses in Kong'

products:
    - gateway

works_on:
    - on-prem
    - konnect


topologies:
  on_prem:
    - hybrid
    - db-less
    - traditional
  konnect_deployments:
    - hybrid
    - cloud-gateways
    - serverless
icon: proxy-cache.png

categories:
  - traffic-control

search_aliases:
  - proxy caching
  - proxy-cache

tags:
  - traffic-control
  - caching

related_resources:
  - text: Proxy Cache Advanced plugin
    url: /plugins/proxy-cache-advanced/
  - text: GraphQL Proxy Cache Advanced plugin
    url: /plugin/graphql-proxy-cache-advanced/
---

The Proxy Cache plugin provides a reverse proxy cache implementation for {{site.base_gateway}}. 
It caches response entities based on a configurable response code and content type, as well as request method.

The advanced version of this plugin, [Proxy Cache Advanced](/plugins/proxy-cache-advanced/), 
extends the Proxy Cache plugin with Redis and Redis Sentinel support.

## How it works

The Proxy Cache plugin stores cache data in memory, which is a shared dictionary defined in [`config.memory.dictionary_name`](./reference/#schema--config-memory-dictionary-name).

The default dictionary, `kong_db_cache`, is also used by other plugins and functions of {{site.base_gateway}} to store unrelated database cache entities.
Using the `kong_db_cache` dictionary is an easy way to bootstrap and test the plugin, but we don't recommend using it for large-scale installations as significant usage will put pressure on other facets of {{site.base_gateway}}'s database caching operations. 
In production, we recommend defining a custom `lua_shared_dict` via a custom Nginx template.

Cache entities are stored for a [configurable period of time](./reference/#schema--config-cache-ttl), after which subsequent requests to the same resource will fetch and store the resource again. 

In Traditional Mode, cache entities can also be [forcefully purged via the Admin API](#managing-cache-entities) prior to their expiration time.

### Cache key

{{site.base_gateway}} keys each cache element based on:
* The request method
* The full client request (for example, the request path and query parameters)
* The UUID of either the API or Consumer associated with the request

Caches are distinct between APIs and Consumers. 

Internally, cache keys are generated by computing the SHA256 hash of the combined parts, then encoding the result in hexadecimal:

```
key = sha256(UUID | method | request | query_params | headers)
```

Where:
* `method` is defined in the OpenResty `ngx.req.get_method()` call
* `query_params` is defined in the OpenResty `ngx.req.get_uri_args()` call
* `headers` are defined in the OpenResty `ngx.req.get_headers()` call 
* `request` is defined via the Nginx `$request` variable
 
{{site.base_gateway}} will return the cache key associated with a given request as the `X-Cache-Key` response header. 

{:.info}
> **Note:** The cache key format is hardcoded and can't be modified. 

### Cache control

When the [`config.cache_control`](./reference/#schema--config-cache-control) configuration option is enabled, 
{{site.base_gateway}} respects request and response Cache-Control headers as 
defined by [RFC7234](https://tools.ietf.org/html/rfc7234#section-5.2), with the following exceptions:

* Cache revalidation is not supported, so directives such as `proxy-revalidate` are ignored
* The behavior of `no-cache` is simplified to exclude the entity from being cached entirely

### Cache status

{% include_cached /plugins/caching/cache-header.md %}

## Storage TTL

{{site.base_gateway}} can store resource entities in the storage engine longer than the set [`config.cache_ttl`](./reference/#schema--config-cache-ttl) or `Cache-Control` values indicate. 
This allows {{site.base_gateway}} to maintain a cached copy of a resource past its expiration. 

If clients use the `max-age` and `max-stale` headers, they can request stale copies of data.

## Upstream outages

If an upstream is unreachable, {{site.base_gateway}} can serve cache data instead of returning an error. 
However, this requires managing stale cache data.

We recommend setting a high [`storage_ttl`](./reference/#schema--config-storage-ttl) value measured in hours or days to store stale data in the cache.  
If an upstream service becomes unavailable, you can increase the [`cache_ttl`](./reference/#schema--config-cache-ttl) value to treat the stale data as fresh.  
This allows {{site.base_gateway}} to serve previously cached data to clients before attempting to connect to the unavailable upstream service.

## Managing cache entities

{% include_cached /plugins/caching/api.md name=page.name slug=page.slug %}
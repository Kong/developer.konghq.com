description: Block specific LLM responses based on semantic similarity to defined rules.

extended_description: |
  The AI Semantic Response Guard plugin analyzes the full response from an LLM service and blocks it
  if it semantically matches one of the configured deny patterns.

  Responses that do not match any deny pattern are permitted.

title: 'Deny only responses'

weight: 900

requirements:
  - "[AI Proxy plugin](/plugins/ai-proxy/) or [AI Proxy Advanced plugin](/plugins/ai-proxy-advanced/) configured with an LLM service."
  - "A [Redis](https://redis.io/docs/latest/) instance or another supported vector database."
  - "Port `6379`, or your custom Redis port, is open and reachable from {{site.base_gateway}}."

variables:
  header_value:
    value: $OPENAI_API_KEY
    description: Your OpenAI API key
  redis_host:
    value: $REDIS_HOST
    description: The host where your Redis instance runs

config:
  embeddings:
    auth:
      header_name: Authorization
      header_value: Bearer ${header_value}
    model:
      name: text-embedding-3-small
      provider: openai
  search:
    threshold: 0.7
  vectordb:
    strategy: redis
    distance_metric: cosine
    threshold: 0.7
    dimensions: 1024
    redis:
      host: ${redis_host}
      port: 6379
  rules:
    deny_responses:
      - Hacking techniques or penetration testing without authorization
      - Bypassing software licensing or digital rights management
      - Instructions on exploiting vulnerabilities or writing malware
      - Circumventing security controls or access restrictions
      - Gathering personal or confidential employee information
      - Using AI to impersonate or phish others
      - Social engineering tactics or manipulation techniques
      - Guidance on violating company IT policies
      - Content unrelated to work, such as entertainment or dating
      - Political, religious, or sensitive non-work-related discussions

tools:
  - deck
  - admin-api
  - konnect-api
  - kic
  - terraform

{
  "3.10.0.0": [
    {
      "message": "Added support for boto3 SDKs for Bedrock provider, and for Google GenAI SDKs for Gemini provider.\n",
      "type": "feature",
      "scope": "Plugin"
    }
  ],
  "3.9.0.0": [
    {
      "message": "Fixed an issue where the *ai-prompt-guard* plugin could fail when handling requests with multiple models.",
      "type": "bugfix",
      "scope": "Plugin"
    }
  ],
  "3.8.0.0": [
    {
      "message": "allow AI plugin to read request from buffered file",
      "type": "feature",
      "scope": "Plugin"
    },
    {
      "message": "add `match_all_roles` option to allow match all roles in addition to `user`.",
      "type": "feature",
      "scope": "Plugin"
    },
    {
      "message": "Fixed an issue when `allow_all_conversation_history` is set to false, the first user request is selected instead of the last one.",
      "type": "bugfix",
      "scope": "Plugin"
    }
  ],
  "3.7.0": [
    {
      "message": "Increased the maximum length of regex expressions to 500 for the allow and deny parameters.\n",
      "scope": "Plugin",
      "type": "feature"
    }
  ],
  "3.7.0.0": [
    {
      "message": "Improve error handling in AI plugins.\n",
      "type": "bugfix",
      "scope": "Plugin"
    }
  ],
  "3.6.0.0": [
    {
      "message": "Introduced the new **AI Prompt Guard** which can allow and/or block  LLM requests based on pattern matching.",
      "type": "feature",
      "scope": "Plugin"
    }
  ]
}
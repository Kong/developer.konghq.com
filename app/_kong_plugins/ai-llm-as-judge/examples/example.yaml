description: 'Evaluate responses by assigning a precise correctness score for AI-assisted learning and assessment.'

extended_description: |
    Evaluate responses by assigning a precise correctness score for AI-assisted learning and assessment.

    Check this [how-to guide](/how-to/compare-llm-models-accuracy/) to see how the plugin works in a real-life scenario.

title: 'Configure the AI LLM as Judge plugin'

weight: 900

requirements:
  - You have a working OpenAI API key
  - You have enabled [AI Proxy](/plugins/ai-proxy) or the [AI Proxy Advanced](/plugins/ai-proxy-advanced) plugin

config:
  config:
    prompt: |
      You are a strict evaluator. You will be given a request and a response.
      Your task is to judge whether the response is correct or incorrect. You must
      assign a score between 1 and 100, where: 100 represents a completely correct
      and ideal response, 1 represents a completely incorrect or irrelevant response.
      Your score must be a single number only â€” no text, labels, or explanations.
      Use the full range of values (e.g., 13, 47, 86), not just round numbers like
      10, 50, or 100. Be accurate and consistent, as this score will be used by another
      model for learning and evaluation.
    http_timeout: 60000
    https_verify: true
    ignore_assistant_prompts: true
    ignore_system_prompts: true
    ignore_tool_prompts: true
    sampling_rate: 1
    llm:
      auth:
        allow_override: false
        header_name: Authorization
        header_value: Bearer ${openai_api_key}
      logging:
        log_payloads: true
        log_statistics: true
      model:
        name: gpt-4o
        provider: openai
        options:
          temperature: 2
          max_tokens: 5
          top_p: 1
          cohere:
            embedding_input_type: classification
      route_type: llm/v1/chat
    message_countback: 3
variables:
  openai_api_key:
    value: $OPENAI_API_KEY

tools:
  - deck
  - admin-api
  - konnect-api
  - kic
  - terraform
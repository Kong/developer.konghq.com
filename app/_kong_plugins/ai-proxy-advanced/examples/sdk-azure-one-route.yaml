title: 'OpenAI SDK: One chat route with dynamic Azure OpenAI deployments'
description: Configure a dynamic route to target multiple Azure OpenAI model deployments.
extended_description: |
  Configure a dynamic route to target multiple Azure OpenAI model deployments.

  In this configuration, if your SDK sends requests to `http://localhost:8000/openai/deployments/my-gpt-3-5/chat/completions`
  then AI Proxy Advanced automatically maps `my-gpt-3-5` as the Azure deployment ID.

  This allows a single Route to support multiple Azure model deployments dynamically.

    {:.warning}
    > For this configuration to work properly, you need a [Route](/gateway/entities/route/#set-up-a-route) with the following configuration:
    > ```
    > routes:
    >  - name: azure-chat-model-from-path
    >    paths:
    >      - "~/openai/deployments/azure-gpt-3-5/chat/completions$"
    >    methods:
    >      - POST
    > ```
weight: 102

requirements:
- Azure OpenAI Service account

config:
  targets:
    - route_type: llm/v1/chat
      auth:
        header_name: api-key
        header_value: ${azure_key}
      logging:
        log_statistics: true
        log_payloads: false
      model:
        provider: azure
        name: $(uri_captures.azure_instance)
        options:
          azure_instance: my-openai-instance
          azure_deployment_id: $(uri_captures.azure_instance)

variables:
  azure_key:
    value: $AZURE_API_KEY
    description: The API key used to authenticate requests to Azure OpenAI Service.

tools:
  - deck
  - admin-api
  - konnect-api
  - kic
  - terraform

group: open-ai
title: 'OpenAI SDK: Chat route with dynamic Azure OpenAI deployments'
description: Configure two static routes to target two specific Azure OpenAI model deployments.
extended_description: |
    Configure two static routes to target two specific Azure OpenAI model deployments.

    Each route uses a predefined deployment ID and model name. This setup is useful when you know the deployments you want to expose through the AI Proxy Advanced plugin.

    For example, one target connects to a `gpt-35-turbo` deployment (`my-gpt-3-5`), and the other connects to a `gpt-4` deployment (`my-gpt-4`).

weight: 101

requirements:
- Azure OpenAI Service account

config:
  targets:
    - route_type: llm/v1/chat
      auth:
        header_name: api-key
        header_value: Bearer ${azure_key}
      logging:
        log_statistics: true
        log_payloads: false
      model:
        provider: azure
        name: gpt-35-turbo
        options:
          azure_instance: my-openai-instace
          azure_deployment_id: my-gpt-3-5
    - route_type: llm/v1/chat
      auth:
        header_name: api-key
        header_value: Bearer ${azure_key}
      logging:
        log_statistics: true
        log_payloads: false
      model:
        provider: azure
        name: gpt-4
        options:
          azure_instance: my-openai-instace
          azure_deployment_id: my-gpt-4

variables:
  azure_key:
    value: $AZURE_API_KEY
    description: The API key used to authenticate requests to Azure OpenAI Service.

tools:
  - deck
  - admin-api
  - konnect-api
  - kic
  - terraform

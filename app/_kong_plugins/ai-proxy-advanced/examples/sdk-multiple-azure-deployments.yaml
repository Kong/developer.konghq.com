title: "OpenAI SDK: Multi-deployment chat routing"
description: Use separate Routes to map Azure OpenAI SDK requests to specific deployments of GPT-4o and GPT-4-1-mini.
extended_description: |
  Use separate Routes to map Azure OpenAI SDK requests to specific deployments of GPT-4o and GPT-4-1-mini.

  Using OpenAI SDK with the AI Proxy Advanced plugin, you can configure multiple Routes in {{site.base_gateway}} to represent different Azure OpenAI deployments.
  Each Route maps a unique path segment (such as `azure-gpt-3-5` or `azure-gpt-4`) to the corresponding deployment ID and model name.
  This setup allows you to use a single Azure-compatible OpenAI SDK client to switch between deployments by changing only the base URL.

  For example:

  ```python
  client = OpenAI(
    base_url="http://127.0.0.1:8000/openai/deployments/azure-gpt-3-5"
  )
  ```

  Or:

  ```python
  client = OpenAI(
    base_url="http://127.0.0.1:8000/openai/deployments/azure-gpt-4o"
  )
  ```
  {{site.base_gateway}} reads the deployment path, maps it to the appropriate Azure deployment ID and model, and handles authentication automatically.

    {:.warning}
    > For this configuration to work properly, you need a [Route](/gateway/entities/route/#set-up-a-route) with the following configuration:
    > ```
    > routes:
    >  - name: azure-chat-gpt-4-1-mini
    >    paths:
    >      - "~/openai/deployments/azure-gpt-4-1-mini/chat/completions$"
    >    methods:
    >      - POST
    > ```
    > and:
    > ```
    > routes:
    >  - name: azure-chat-gpt-4o
    >    paths:
    >      - "~/openai/deployments/azure-gpt-4o/chat/completions$"
    >    methods:
    >      - POST
    > ```

  For a complete tutorial of this configuration, see the [Azure OpenAI SDK example](/how-to/route-azure-sdk-to-specific-deployments).
weight: 106

requirements:
- Azure account

config:
  - targets:
    - route_type: llm/v1/chat
      auth:
        header_name: "api-key"
        header_value: ${azure_key}
      logging:
        log_statistics: true
        log_payloads: false
      model:
        provider: "azure"
        name: "gpt-4o"
        options:
          zure_instance: ${azure_instance}
          azure_deployment_id: ${azure_deployment}
  - targets:
    - route_type: llm/v1/chat
      auth:
        header_name: "api-key"
        header_value: ${azure_key}
      logging:
        log_statistics: true
        log_payloads: false
      model:
        provider: "azure"
        name: "gpt-4-1-mini"
        options:
          azure_instance: ${azure_instance}
          azure_deployment_id:  ${azure_deployment}

variables:
  azure_key:
    value: $AZURE_API_KEY
    description: The API key to authenticate requests to Azure.
  azure_instance:
    value: $AZURE_INSTANCE
    description: The name of your Azure OpenAI instance.
  azure_deployment:
    value: $AZURE_DEPLOYMENT
    description: The deployment ID of the Azure OpenAI model you want to use.


tools:
  - deck
  - admin-api
  - konnect-api
  - kic
  - terraform

group: open-ai
title: 'Set up with OpenAI and PGVector'

description: 'Enable AI Semantic Caching with OpenAI embeddings API and a PGVector database.'

extended_description: |

  Enable AI Semantic Caching with OpenAI embeddings API and a PGVector database.

  {:.info}
  > If you use the `text-embedding-ada-002` as an embedding model, you must set a fixed dimension of `1536`, as required by the official model specification. Alternatively, use the `text-embedding-3-small` model, which supports dynamic dimensions and works without specifying a fixed value.

weight: 900
requirements:
  - "The [AI Proxy](/plugins/ai-proxy/) or [AI Proxy Advanced](/plugins/ai-proxy-advanced/) plugin is enabled"
  - An OpenAI account
  - A PostgreSQL server with the [PGVector](https://github.com/pgvector/pgvector) extension installed

variables:
  header_value:
    value: $OPENAI_API_KEY
    description: Your OpenAI API key

config:
  embeddings:
    auth:
      header_name: Authorization
      header_value: ${header_value}
    model:
      provider: openai
      name: text-embedding-3-large
      options:
        upstream_url: https://api.openai.com/v1/embeddings
  vectordb:
    dimensions: 3072
    distance_metric: cosine
    strategy: pgvector
    threshold: 0.1
    pgvector:
      host: pgvector.pgvector.svc.cluster.local
      port: 5432
      database: kong
      user: kong

tools:
  - deck
  - admin-api
  - konnect-api
  - kic
  - terraform
{
  "3.13.0.0": [
    {
      "message": "deprecate config.rules.max_request_body_size with config.max_request_body_size.",
      "scope": "Plugin",
      "type": "bugfix"
    }
  ],
  "3.12.0.0": [
    {
      "message": "Fixed the deletion of guard instances and improved error handling.\n",
      "type": "bugfix",
      "scope": "Plugin"
    }
  ],
  "3.11.0.0": [
    {
      "message": "Fixed an issue where some of ai metrics was missed in analytics",
      "scope": "Plugin",
      "type": "bugfix"
    },
    {
      "message": "If any [AI Gateway plugin](/plugins/?category=ai) has been enabled in a self-managed Kong Gateway deployment for more than a week, upgrades from 3.10 versions to 3.11.0.0 will fail due to a license migration issue. This does not affect Konnect deployments.\n\nA fix will be provided in 3.11.0.1.\n\nSee [breaking changes in 3.11](/gateway/breaking-changes/#known-issues-in-3-11-0-0) for a temporary workaround.",
      "type": "known-issues",
      "scope": "Plugin"
    }
  ],
  "3.11.0.1": [
    {
      "message": "Fixed an issue where the llm license migration could fail if the license counter contained more than one week of data.",
      "scope": "Plugin",
      "type": "bugfix"
    }
  ],
  "3.11.0.2": [
    {
      "message": "Fixed an issue where Gemini Vertex AI embeddings failed due to incorrect URL construction and response parsing.\n",
      "type": "bugfix",
      "scope": "Plugin"
    }
  ],
  "3.10.0.0": [
    {
      "message": "Fixed an issue where Kong Gateway was not able to reconfigure the plugin when using DB-less mode.\n",
      "type": "bugfix",
      "scope": "Plugin"
    }
  ],
  "3.10.0.4": [
    {
      "message": "Fixed an issue where the Gemini provider could not use Anthropic 'rawPredict' endpoint models hosted in Vertex.",
      "type": "bugfix",
      "scope": "Plugin"
    },
    {
      "message": "Fixed an issue where Gemini Vertex AI embeddings failed due to incorrect URL construction and response parsing.\n",
      "type": "bugfix",
      "scope": "Plugin"
    }
  ],
  "3.9.1.0": [
    {
      "message": "Fixed an issue where the plugin was not able to reconfigure the plugin when using DB-less mode.\n",
      "type": "bugfix",
      "scope": "Plugin"
    }
  ],
  "3.9.0.0": [
    {
      "message": "Made the\n`embeddings.model.name` config field a free text entry, enabling use of a\nself-hosted (or otherwise compatible) model.\n",
      "type": "feature",
      "scope": "Plugin"
    },
    {
      "message": "Fixed an issue where stale plugin config was not updated in dbless and hybrid mode.",
      "type": "bugfix",
      "scope": "Plugin"
    },
    {
      "message": "Fixed an issue where requests with multiple models caused failures.",
      "type": "bugfix",
      "scope": "Plugin"
    }
  ],
  "3.8.1.0": [
    {
      "message": "Fixed an issue where stale plugin config was not updated in dbless and hybrid mode.",
      "type": "bugfix",
      "scope": "Plugin"
    }
  ],
  "3.8.0.0": [
    {
      "message": "allow AI plugin to read request from buffered file",
      "type": "feature",
      "scope": "Plugin"
    },
    {
      "message": "Added the `ai-semantic-prompt-guard` plugin that supports semantic similarity-based prompt guarding.",
      "type": "feature",
      "scope": "Plugin"
    }
  ]
}
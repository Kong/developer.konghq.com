
title: 'Chat route with Llama2'
description: 'Configure a chat route using a local Llama2 model with the OLLAMA format.'

weight: 900

# requirements: <- not required
# - "some req"

# variables: <- not required
#   my-region:
#     description: ''
#     value: us

config:
  route_type: llm/v1/chat
  model:
    provider: llama2
    name: llama2
    options:
      llama2_format: ollama
      upstream_url: http://llama2-server.local:11434/api/chat

title: 'Chat route with Llama 2'
description: 'Configure a chat route using a local Llama 2 model with the OLLAMA format.'

weight: 900

requirements:
- A local Llama 2 instance

config:
  route_type: llm/v1/chat
  model:
    provider: llama2
    name: llama2
    options:
      llama2_format: ollama
      upstream_url: http://llama2-server.local:11434/api/chat

tools:
  - deck
  - admin-api
  - konnect-api
  - kic
  - terraform

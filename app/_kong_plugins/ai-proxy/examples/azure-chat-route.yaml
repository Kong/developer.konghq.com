title: 'Chat route with Azure OpenAI Service'
description: 'Configure a chat route using Azure OpenAI Service with the GPT-4o model.'

extended_description: |
  Configure a chat route using Azure OpenAI Service with the GPT-4o model.

  To connect to Azure AI, you'll need three values from your Azure OpenAI resource:

  1. **Deployment ID** — The unique name of your deployed model.
     - In the [Azure AI Foundry Portal](https://ai.azure.com/?cid=learnDocs) sidebar, select a resource and go to:
       **Shared Resources > Deployments > Model deployments**, then click the deployment name.
     - You can also see the deployment ID in the Azure OpenAI URL when calling the API, for example:
       `https://{AZURE_INSTANCE_NAME}.openai.azure.com/openai/deployments/{AZURE_DEPLOYMENT_ID}/...`

  2. **Instance name** — The name of your Azure OpenAI resource.
     - This is the prefix in your API endpoint URL, for example:
       `https://{AZURE_INSTANCE_NAME}.openai.azure.com`
  3. **API Key** — The key used to authenticate requests to your Azure OpenAI deployment in Azure AI Foundry.
     - In the [Azure AI Foundry Portal](https://ai.azure.com/?cid=learnDocs) sidebar, select a resource and go to:
       **Shared Resources > Deployments > Model deployments**, then click the deployment name.
     - The API key is visible in the **Endpoint** tile.

weight: 900

config:
  model_name_header: false
  route_type: llm/v1/batches
  auth:
    header_name: Authorization
    header_value: Bearer ${azure_key}
  model:
    provider: azure
  options:
    azure_api_version: "2025-01-01-preview"
    azure_instance: ${azure_instance}
    azure_deployment_id: ${azure_deployment}
variables:
  azure_key:
    value: "$AZURE_OPENAI_API_KEY"
  azure_instance:
    value: "$AZURE_INSTANCE_NAME"
  azure_deployment:
    value: "$AZURE_DEPLOYMENT_ID"

tools:
  - deck
  - admin-api
  - konnect-api
  - kic
  - terraform

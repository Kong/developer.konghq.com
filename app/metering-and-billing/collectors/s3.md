---
title: "S3 Collector"
content_type: reference
description: "Learn how to use the S3 collector to meter usage from S3-compatible object storage in {{site.konnect_short_name}} {{site.metering_and_billing}}."
layout: reference
products:
  - metering-and-billing
tools:
    - konnect-api
works_on:
  - konnect
breadcrumbs:
  - /metering-and-billing/
  - /metering-and-billing/collectors/
related_resources:
  - text: "{{site.konnect_short_name}} {{site.metering_and_billing}}"
    url: /metering-and-billing/
  - text: "Collectors"
    url: /metering-and-billing/collectors/
---

The OpenMeter Collector can import data from an S3-compatible object storage, making integration easier with existing data pipelines. Examples of popular S3-compatible object stores:

* [AWS S3](https://aws.amazon.com/s3)
* [Cloudflare R2](https://developers.cloudflare.com/r2)
* [Backblaze B2](https://www.backblaze.com/cloud-storage)

This guide will show you how to collect data from an S3-compatible object store and ingest it into {{site.metering_and_billing}}.

## Prerequisites

There are several strategies to collect data from an S3-compatible object store, but all of them depend on how the data is stored. 
Since we cannot possibly cover all possible scenarios, we will provide a solution for the most common one: batches of data indexed by timestamps.

If your data is not structured that way, check out the [aws_s3](https://docs.redpanda.com/redpanda-connect/components/inputs/aws_s3) Redpanda Connect input documentation for more options.

## Configuration

First, create a new YAML file for the collector configuration. You will use the `aws_s3` Redpanda Connect input:

```yaml
input:
  aws_s3:
    bucket: my-bucket
    region: us-east-1
    prefix: ${!timestamp_unix().ts_round("1h".parse_duration()).ts_unix()}/
```

The above section will tell Redpanda Connect to read data from your S3 bucket in the specified region and look for objects in the specified prefix (hourly timestamp). You will have to run the collector as a cron job every hour to ingest the data into {{site.metering_and_billing}}.

Feel free to tweak the prefix to your needs.

Next, configure the mapping from your schema to [CloudEvents](https://cloudevents.io/) using [bloblang](https://docs.redpanda.com/redpanda-connect/guides/bloblang/about):

```yaml
pipeline:
  processors:
    - mapping: |
        root = {
          "id": this.id,
          "specversion": "1.0",
          "type": "your-usage-event-type",
          "source": "s3",
          "time": this.time,
          "subject": this.subject_field,
          "data": {
            "data": this.data_field,
          },
        }
```

Finally, configure the output:

```yaml
output:
  label: 'openmeter'
  drop_on:
    error: false
    error_patterns:
      - Bad Request
  output:
    http_client:
      url: '${OPENMETER_URL:https://us.api.konghq.com}/v3/openmeter/events'
      verb: POST
      headers:
        Authorization: 'Bearer ${OPENMETER_TOKEN:}'
        Content-Type: 'application/json'
      timeout: 30s
      retry_period: 15s
      retries: 3
      max_retry_backoff: 1m
      max_in_flight: 64
      batch_as_multipart: false
      drop_on:
        - 400
      batching:
        count: 100
        period: 1s
        processors:
          - metric:
              type: counter
              name: openmeter_events_sent
              value: 1
          - archive:
              format: json_array
      dump_request_log_level: DEBUG
```

## Installation

Check out the [Collectors overview](/metering-and-billing/collectors/) for installation instructions.

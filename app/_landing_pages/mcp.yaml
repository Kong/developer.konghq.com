metadata:
  title: "MCP Traffic Gateway"
  content_type: landing_page
  description: This page is an introduction to MCP Traffic Gateway capabilites in Kong AI Gateway.
  products:
    - ai-gateway
    - gateway
  works_on:
    - on-prem
    - konnect
  tags:
    - ai

rows:
  - header:
      type: h1
      text: "A trust and control layer for proxing traffic to MCP servers"
      sub_text: Gain control and visibility over AI agent infrastructure with AI Gateway-driven MCP capabilities

  - header:
      type: h2
      text: Bring MCP servers to production securely with Kong AI Gateway
    columns:
      - blocks:
          - type: text
            config: |
              AI agents are rapidly becoming core components of modern software, driving the need for structured, reliable interfaces to access tools and data. The Model Context Protocol (MCP) addresses this by enabling agents to reason, plan, and act across services. However, scaling MCP in remote, distributed environments introduces new operational challenges.

              Key concerns like authentication, context propagation, load balancing, and service discovery are familiar to those working in API infrastructure. As such, the API gateway—already proven in securing and scaling HTTP services—offers a strong foundation for bringing MCP to production.

              Kong’s AI Gateway extends these capabilities to MCP. By applying established gateway patterns to emerging agent interfaces, Kong AI Gateway enables teams to manage remote MCP traffic with enterprise-grade security, performance, and developer experience.

      - blocks:
          - type: image
            config:
              url: /assets/images/gateway/mcp-architecture.svg
              alt_text: Overview of AI gateway
      # - blocks:
      #     - type: mermaid
      #       config:
      #         diagram: |
      #           flowchart LR
      #             %% MCP Client at the top
      #             client(((MCP Client)))

      #             %% External systems

      #             server[[MCP Server]]
      #             upstream([Upstream APIs])
      #             llm([LLM])

      #             %% Gateway Layer: all proxies inside
      #             subgraph Gateway_Layer ["AI Gateway"]
      #                 direction TB
      #                 proxy_llm[AI proxy]
      #                 proxy_server[AI proxy]
      #                 proxy_upstream[AI proxy]
      #             end

      #             %% Simulated merge point
      #             merge_point(( #8648; ))

      #             %% Flows
      #             server -->|Context/tool data| proxy_server --> merge_point
      #             merge_point --> client
      #             llm -->|Prompt/tool result| proxy_llm --> merge_point
      #             upstream -->|Tool call execution| proxy_upstream <--> server

      #             %% Styles
      #             style proxy_llm stroke-dasharray: 3 3
      #             style proxy_server stroke-dasharray: 3 3
      #             style proxy_upstream stroke-dasharray: 3 3
      #             style Gateway_Layer fill:#ffffff00,stroke-dasharray: 5 5

  # - columns:
  #     - blocks:
  #       - type: card
  #         config:
  #           title: Secure and govern MCP traffic
  #           description: Learn how you can
  #           icon: /assets/icons/mcp.svg
  #           cta:
  #             url: /mcp/get-started/
  #             align: end
  #     - blocks:
  #       - type: card
  #         config:
  #           title: Get started
  #           description: Learn how to run the Kong {{site.konnect_product_name}} MCP Server with Claude.
  #           icon: /assets/icons/rocket.svg
  #           cta:
  #             url: /mcp/get-started/
  #             align: end

  - columns:
      - blocks:
          - type: structured_text
            config:
              header:
                type: h2
                text: "User paths"
              blocks:
                - type: text
                  text: |
                    Whether you're using your own MCP server or getting started with Kong's built-in MCP server, Kong AI Gateway makes it easy to secure, govern, and scale AI-native traffic.
  - header:
    columns:
      - blocks:
          - type: structured_text
            config:
              header:
                type: h4
                text: "Secure and govern your MCP server with Kong AI Gateway"
              blocks:
                - type: text
                  text: |
                    To expose an MCP server in production, you must secure access, govern usage, optimize cost, and observe behavior. Kong AI Gateway provides the policy framework to do exactly that:

                    - **Secure access** with authentication plugins like OpenID Connect or Key Auth.
                    - **Govern usage** with rate limiting policies based on tokens or request volume.
                    - **Optimize cost** by enforcing token-based quotas and blocking overuse at the edge.
                    - **Observe behavior** with logging and tracing powered by OpenTelemetry.

      - blocks:
          - type: structured_text
            config:
              header:
                type: h4
                text: "Have conversational control of {{site.konnect_product_name}} with Kong MCP Server"
              blocks:
                - type: text
                  text: |
                      Want to quickly test MCP workflows with Claude? Kong MCP Server makes it easy to connect AI assistants to {{site.konnect_product_name}}. Use natural language to access key tools like analytics, configuration inspection, and control plane management:
                      * Query API analytics with customizable filters
                      * List and inspect services, routes, consumers, and plugins
                      * Manage control planes and control plane groups
                      * Integrate with Claude and other MCP-compatible AI assistants

  - columns:
    - blocks:
      - type: card
        config:
          icon: /assets/icons/mcp.svg
          title: Secure and govern your MCP traffic
          description: |
            Follow the tutorials below to learn how to secure, govern, and observe your MCP traffic using Kong AI Gateway.
          ctas:
            - text: Start securing your MCP traffic now
              url: "/mcp/"
            - text: Take control of your MCP traffic governance
              url: "/mcp/"
            - text: Monitor your MCP traffic
              url: "/mcp/"
    - blocks:
      - type: card
        config:
          icon: /assets/icons/rocket.svg
          title: Use Kong Konnect MCP Server
          description: |
            Follow the tutorials below to get started with Kong Konnect MCP Server using GitHub setup or Docker deployment, plus explore available tools.
          ctas:
            - text: Get started with Kong Konnect MCP Server
              url: "/mcp/get-started"
            - text: Get started with Kong MCP server using Docker
              url: "https://hub.docker.com/r/mcp/kong"
            - text: Check available tools
              url: "/mcp/tools"


  - header:
      type: h2
      text: How-to Guides

    columns:
      - blocks:
          - type: how_to_list
            config:
              tags:
                - ai
              quantity: 5
              allow_empty: true

  - header:
      text: "Frequently Asked Questions"
      type: h2
    columns:
      - blocks:
        - type: faqs
          config:
            - q: Question 1
              a: |
                Yes

            - q: Question 2
              a: |
                Yes

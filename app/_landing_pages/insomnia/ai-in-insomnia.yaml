metadata:
  title: AI in Insomnia
  content_type: landing_page
  description: Explore AI features in Insomnia 12, including MCP Servers, AI-assisted mock servers, and commit suggestions. Learn how to connect, configure, and manage AI integrations across your workspace.
  breadcrumbs:
    - /insomnia/
  products:
    - insomnia
  min_version:
    insomnia: '12.0'  
rows:
  - header:
      type: h1
      text: "AI in Insomnia"
      sub_text: Explore the AI features available in Insomnia and learn how they enhance automation, collaboration, and productivity.
    columns:
      - blocks:
          - type: structured_text
            config:
              header:
                text:
              blocks:
                - type: text
                  text: |
                    {:.decorative}
                    > As of Insomnia v12, AI features are free to use, though this may change in future releases.

                    Insomnia 12 introduces a suite of **AI-driven capabilities** that make API development faster, smarter, and more collaborative. These include:
                    - [**MCP Servers and Clients**](/insomnia/mcp-servers/#mcp-servers-and-clients), which connect to external AI-ready tools and resources.  
                    - [**AI-assisted mock server generation**](/insomnia/mcp-servers/#ai-assisted-mock-servers), which transforms prompts or API definitions into mock APIs.  
                    - [**AI commit message suggestions**](/mcp-servers/#ai-driven-git-commits), which help maintain clear and atomic commit histories.

                    Activate these features by enabling a **Large Language Model (LLM)** in **Preferences > AI Settings**.  
                    Choose from one of the following providers:
                    - **Local**
                    - **Claude**
                    - **OpenAI**
                    - **Gemini**

                    {:.info}
                    > Local models keep processing fully on your machine for privacy and control, but may run slower and produce less-refined responses than hosted models.
  - header:
      type: h2
      text: "AI features overview"
    columns:
      - blocks:
          - type: structured_text
            config:
              header:
                text:
              blocks:
                - type: text
                  text: |
                    Once an LLM is activated, Insomnia unlocks multiple AI features that are designed to automate repetitive workflows, generate content dynamically, and enhance collaboration.

                    {% table %}
                    columns:
                      - title: Feature
                        key: feature
                      - title: Description
                        key: description
                      - title: Product context
                        key: context
                    rows:
                      - feature: "Auto-generate Mock Servers from natural language"
                        description: "Creates a mock server from a prompt, OpenAPI definition, or live URL response. Automatically scaffolds routes, responses, and configurations."
                        context: "Available when creating **Self-hosted** mock servers. See [**Mock Servers**](/insomnia/mock-servers/)."
                      - feature: "Suggest comments and grouping for Commits"
                        description: "Analyzes staged Git changes and suggests logical commit groupings and draft messages."
                        context: "Available in the **Git Sync** interface. See [**Version control in Insomnia**](/insomnia/version-control/)."
                      - feature: "MCP Client operations"
                        description: "Connect to MCP Servers that expose callable tools, prompts, and structured resources via JSON-RPC. See [**MCP clients in Insomnia**](/insomnia/mcp-clients-in-insomnia/)."
                        context: "Manage connections under **MCP Servers** in Insomnia."
                    {% endtable %}

  - header:
      type: h2
      text: "Configure and manage AI"
    columns:
      - blocks:
          - type: structured_text
            config:
              header:
                text:
              blocks:
                - type: text
                  text: |
                    Activate features by choosing and uploading an LLM in Preferences > AI Settings:

                    1. Click **Preferences**.  
                    2. Select the **AI Settings** tab.  
                    3. In the provider list, choose a LLM type: 
                    - **Local LLM**: In the **Model** dropdown, click **Select a model**, and then choose a model.
                    - **Claude**: Insert API key, and click **Load Models**.
                    - **OpenAI**: Insert API key, and click **Load Models**.
                    - **Gemini**: Insert API key, and click **Load Models**.
                    4. Enter your credentials or local model path.  
                    5. Click **Activate**.

                    After activation, toggles for **Auto-generate Mock Servers** and **Suggest commit comments** become available.

                    {:.decorative}
                    > **Tip**: For Local type LLM, add `.gguf` model files to your **LLMs** folder, and then select the **Refresh** icon to re-scan and make them available in the **Model** list.

                    **Administrative controls:**
                    - Instance-level AI settings are available in **Insomnia Admin > AI Settings**.  
                    - **Essentials** and **Pro** plans: AI features are **enabled by default**.  
                    - **Enterprise** plans: AI features are **disabled by default** but can be toggled on.  
                    - Users must still activate a model locally before enabling feature toggles.
  - header:
      type: h2
      text: "MCP Servers and Clients"
    columns:
      - blocks:
          - type: structured_text
            config:
              header:
                text:
              blocks:
                - type: text
                  text: |
                    **Model Context Protocol (MCP)** Servers expose domain-specific operations through a **JSON-RPC interface**. For example:
                      - `tools/CALL`
                      - `resources/READ`
                      - `prompts/GET`

                    When you connect Insomnia to an MCP Server, Insomnia creates an **MCP Client** that acts like a synchronized request group. The client stays updated with tools, prompts, and resources published by the server.

                    **Use MCP Clients to:**
                    - Discover and execute callable tools  
                    - Retrieve structured resources  
                    - Explore and test AI-driven prompts  
                    - Resync data from the server as it changes 

                    **Transports available:** HTTP and STDIO.  
                    
                    {:.info}
                    > Offline mode displays cached data until resync.

          - type: button
            config:
              text: Learn more about MCP Clients
              url: /insomnia/mcp-clients-in-insomnia/
              align: left

  - header:
      type: h2
      text: "AI-assisted Mock Servers"
    columns:
      - blocks:
          - type: structured_text
            config:
              header:
                text:
              blocks:
                - type: text
                  text: |
                    Use Insomnia’s AI-assisted mock server generation to transform a short description, or an existing API source into a working self-hosted mock server. Instead of hand-building dozens of endpoints, Insomnia scaffolds routes, example responses, and base configuration to help you prototype faster and unblock teams.

                    Generate a mock server from one of the following:
                    - **URL**: Generate from a live endpoint response.  
                    - **OpenAPI**: Generate from a spec.  
                    - **Text**: Generate from a natural-language prompt.
                    
                    {:.warning}
                    > AI-generated mock servers only support **Self-hosted** hosting. Cloud-hosted mock servers are currently unsupported.

                    **To create an AI-generated mock server:**
                    1. In your Insomnia project, click **Create**.  
                    2. Click **Mock Server**.  
                    3. Click **Auto-Generate**.  
                    4. Click **URL**, or **OpenAPI spec**, or **Text**. 
                    5. (Optional) Select the **Enable dynamic responses** checkbox.  
                    6. (Optional) Click **+ Add Files** to upload extra JSON files or YAML files.
                    7. Type an example URL.
                    8. Click **Create**.

                    To verify, open the **Mock Tester** tab and send a request. Confirm that the response matches the generated configuration.

                    **AI-assisted mocks and dynamic mocking**: AI generation focuses on creating a complete mock structure from your input prompt or source. [Dynamic mocking](/insomnia/dynamic-mocking/) extends those generated mocks by making them **request-aware**. Vary responses and inject randomized test data using Faker tags.  
                    
                    Together, they enable rapid creation of realistic, responsive test environments without manual setup.

          - type: button
            config:
              text: Learn more about dynamic mocking
              url: /insomnia/dynamic-mocking/
              align: left

  - header:
      type: h2
      text: "AI-driven Git commits"
    columns:
      - blocks:
          - type: structured_text
            config:
              header:
                text: 
              blocks:
                - type: text
                  text: |
                    Insomnia’s **Suggest comments and grouping for Commits** feature analyzes staged changes and helps maintain consistent, meaningful Git histories. For Git concepts and workflows, go to [**Version control in Insomnia**](insomnia/version-control/).

                    **To use commit suggestions:**
                    1. Open the **Git Sync** interface.  
                    2. Click **Suggest comments and grouping for Commits**.  
                    3. Review the suggested commit groups and messages.  
                    4. (Optional) To edit a message inline, double-click the message.  
                    5. Drag and drop files between commit groups, or exclude files.  
                    6. Click **Commit** or **Commit & Push**.

                    Once applied, Insomnia saves your changes locally without re-running AI suggestions.

  - header:
      type: h2
      text: "Frequently asked questions"
    columns:
      - blocks:
          - type: faqs
            config:
              - q: Can I disable AI features for myself?
                a: |
                  Yes. Go to **Preferences → AI Settings** and deactivate the toggles for **Auto-generate Mock Servers** and **Suggest commit comments**.  
                  To stop using an LLM entirely, click **Deactivate** under the provider configuration.
              - q: Why don’t I see AI features in the app?
                a: |
                  You must first configure and activate an LLM under **Preferences → AI Settings**.  
                  If AI is deactivated at the instance level, the feature toggles will remain unavailable in the UI.
              - q: How do I manage AI across my organization?
                a: |
                  Administrators can enable or disable AI features at the instance level from **Insomnia Admin → AI Settings**.  
                  When disabled, the desktop app shows an explanatory message.  
                  When enabled, each user must still activate a model before toggles become available.
              - q: Which transports are supported for MCP Clients?
                a: |
                  Both **HTTP** and **STDIO** transports are supported for connecting to MCP Servers.
              - q: Can MCP Clients use Git Sync or Import/Export?
                a: |
                  Not yet. MCP Clients are stored locally and currently do not support Git Sync or import/export.

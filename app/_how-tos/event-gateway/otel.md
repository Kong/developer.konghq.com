---
title: Set up observability for {{site.event_gateway}}
content_type: how_to
breadcrumbs:
  - /event-gateway/

products:
    - event-gateway

works_on:
    - konnect

tags:
    - observability
    - kafka
    - troubleshooting

description: "Export metrics and traces from {{site.event_gateway}} into your own observability systems using OpenTelemetry (OTEL)."

tldr: 
  q: How do I set see metrics and traces for {{site.event_gateway}}?
  a: |
    Export metrics and traces from {{site.event_gateway}} into your own observability systems using OpenTelemetry (OTEL), which helps you understand how {{site.event_gateway_short}} functions and how to troubleshoot it when something goes wrong.

    In this tutorial, we're using Jaeger and Prometheus, but you can substitute your own preferred tools as well.
tools:
    - konnect-api

faqs:
  - q: What metrics are available for {{site.event_gateway}}?
    a: You can find the list of all available metrics in the [metrics reference](/event-gateway/metrics/).
  
prereqs:
  skip_product: true
  inline:
    - title: Install kafkactl
      position: before
      content: |
        Install [kafkactl](https://github.com/deviceinsight/kafkactl?tab=readme-ov-file#installation). You'll need it to interact with Kafka clusters. 

    - title: Start a local Kafka cluster
      position: before
      include_content: knep/docker-compose-start

related_resources:
  - text: "{{site.event_gateway_short}} Control Plane API"
    url: /api/konnect/event-gateway/
  - text: Event Gateway metrics reference
    url: /event-gateway/metrics/

---

In this guide, you'll configure:

* An [OpenTelemetry (OTEL) collector](https://opentelemetry.io/docs/collector/) to receive data from {{site.event_gateway_short}} and send it to the observability systems.
* [Jaeger](https://www.jaegertracing.io/) for visualizing traces from {{site.event_gateway_short}}.
* [Prometheus](https://prometheus.io/) for visualizing and querying metrics from {{site.event_gateway_short}}.

Here's how it works:

{% mermaid %}
flowchart LR

    A[Traces]
    B[Metrics]
    C[OTLP
    receiver]
    D[Prometheus
    receiver]
    E[Tracing system]
    F[Metrics system]

    subgraph id1 [Event Gateway]
    A
    B
    end

    A --push traces --> C
    B --scrape metrics--> D

    subgraph id2 [OTEL Collector]
    C
    D
    end

    C -- Export traces --> E
    D -- Export metrics --> F
{% endmermaid %}

In this setup:
1. {{site.event_gateway_short}} generates traces and metrics.
1. Using the OTEL collector:
  * The OTLP receiver gathers traces generated by {{site.event_gateway_short}}.
  * The Prometheus receiver ingests the Prometheus-compatible metrics directly from {{site.event_gateway_short}}.
1. We export the data to our Prometheus instance using the OTLP/HTTP exporter, which sends metrics directly to Prometheus’ OTLP endpoint.

## Create an {{site.event_gateway_short}} control plane and data plane

Run the quickstart script to automatically provision a demo {{site.event_gateway_short}} control plane and data plane, and configure your environment for sending metrics and traces:

```sh
curl -Ls https://get.konghq.com/event-gateway | bash -s -- \
  -k $KONNECT_TOKEN \
  -N kafka_event_gateway \
  -e "KEG__OBSERVABILITY__OTLP__TRACING__ENABLED=true" \
  -e "KEG__RUNTIME__HEALTH_LISTENER_ADDRESS_PORT=0.0.0.0:8080" \
  -e "OTEL_EXPORTER_OTLP_PROTOCOL=grpc" \
  -e "OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317" \
  -e "OTEL_EXPORTER_OTLP_TIMEOUT=10s" \
  -e "OTEL_SERVICE_NAME=eventgw"
```

Where you configure the following custom telemetry settings:

{% table %}
columns:
  - title: Parameter
    key: param
  - title: Default
    key: default
  - title: New value
    key: new
  - title: Description
    key: desc
rows:
  - param: "`KEG__OBSERVABILITY__OTLP__TRACING__ENABLED`"
    default: "`false`"
    new: "`true`"
    desc: Determines whether to turn on OTLP tracing.
  - param: "`KEG__RUNTIME__HEALTH_LISTENER_ADDRESS_PORT`"
    default: "`localhost:8080`"
    new: "`0.0.0.0:8080`"
    desc: Determines the address and port for the health listener where metrics are exposed for scraping.
  - param: "`OTEL_EXPORTER_OTLP_PROTOCOL`"
    default: "`http/protobuf`"
    new: "`grpc`"
    desc: Protocol used to export OpenTelemetry data.
  - param: "`OTEL_EXPORTER_OTLP_ENDPOINT`"
    default: "`https://localhost:4317`"
    new: "`http://otel-collector:4317`"
    desc: Endpoint to send OpenTelemetry data. In most cases, this will be an OTEL collector URL.
  - param: "`OTEL_EXPORTER_OTLP_TIMEOUT`"
    default: 10s
    new: 10s
    desc: Max waiting time for the backend to process each metrics batch. We're not adjusting this for the tutorial, but you can adjust as needed for troubleshooting.
  - param: "`OTEL_SERVICE_NAME`"
    default: none
    new: "`eventgw`"
    desc: Name of the OTEL service identified in the observability tools. For example, metrics in Prometheus will be prefixed with `kong_eventgw_*`.
{% endtable %}

This sets up an {{site.event_gateway_short}} control plane named `event-gateway-quickstart`, provisions a local data plane, and prints out the following environment variable export:

```
export EVENT_GATEWAY_ID=your-gateway-id
```

Copy and paste this into your terminal to configure your session.

{% include_cached /knep/quickstart-note.md %}

## Configure the OTEL collector and Prometheus

Next, we need to create two configuration files: one for the OTEL collector, and one for Prometheus.

Open a new terminal window and create a directory for the configuration:
```sh
mkdir otel && cd otel
```

Create an OTEL collector configuration file:

<!--vale off-->
{% validation custom-command %}
command: |
  cat <<EOF > otel-collector-config.yaml
  receivers:
    otlp/keg:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
    prometheus/keg:
      config:
        scrape_configs:
          - job_name: kong
            scrape_interval: 5s
            static_configs:
              - targets: ['kong_event_gateway:8080']

  processors:
    batch: {}

  extensions:
    health_check: {}

  exporters:
    otlp/jaeger:
      endpoint: jaeger:4317
      tls:
        insecure: true
    otlphttp/prometheus:
      endpoint: http://prometheus:9090/api/v1/otlp
      tls:
        insecure: true

  service:
    pipelines:
      traces:
        receivers: [otlp/keg]
        processors: [batch]
        exporters: [otlp/jaeger]
      metrics:
        receivers: [prometheus/keg]
        processors: [batch]
        exporters: [otlphttp/prometheus]
  EOF
expected:
  return_code: 0
render_output: false
{% endvalidation %}
<!--vale on-->

Create a Prometheus configuration file:

<!--vale off-->
{% validation custom-command %}
command: |
  cat <<EOF > prometheus.yaml
  global:
    scrape_interval: 5s

  scrape_configs:
    - job_name: 'prometheus'
      static_configs:
        - targets: ['localhost:9090']
  EOF
expected:
  return_code: 0
render_output: false
{% endvalidation %}
<!--vale on-->

## Launch OTEL collector stack

Now, let's run the OTEL collector stack with Jaeger and Prometheus.

Run the following command to save a Docker compose file, making sure that it communicates on the same network as your Kafka cluster and your {{site.event_gateway_short}} data plane:
```yaml
cat <<EOF > docker-compose.yaml

name: otel-stack
networks:
  kafka_event_gateway:
    external: true

services:
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    networks:
      - kafka_event_gateway
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317"  # OTLP gRPC receiver
      - "18639:9090" # Use this for testing the scraping endpoint
  
  jaeger:
    image: jaegertracing/all-in-one:latest
    networks:
      - kafka_event_gateway
    ports:
      - "6831:6831/udp" # UDP port for Jaeger agent
      - "16686:16686"   # Web UI
      - "14268:14268"   # HTTP port for spans

  prometheus:
    image: prom/prometheus:latest
    networks:
      - kafka_event_gateway
    command:
      - '--config.file=/etc/prometheus/prometheus.yaml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-otlp-receiver'   # Enables Prometheus to receive metrics using OTLP
    volumes:
      - ./prometheus.yaml:/etc/prometheus/prometheus.yaml
    ports:
      - "9090:9090"
EOF
```

Launch the OTEL stack:
```sh
docker compose up -d
```

## Add Kafka configuration

Use the following Kafka configuration to access your Kafka resources from the virtual clusters:

<!--vale off-->
{% validation custom-command %}
command: |
  cat <<EOF > kafkactl.yaml
  contexts:
    direct:
      brokers:
        - localhost:9095
        - localhost:9096
        - localhost:9094
    vc:
      brokers:
        - localhost:19092
  EOF
expected:
  return_code: 0
render_output: false
{% endvalidation %}
<!--vale on-->

## Create entities

* backend cluster, listener, virtual cluster - can we shortcut this somehow?

## Validate the cluster

Create a topic using the `direct` context, which is a direct connection to our Kafka cluster:

{% validation custom-command %}
command: |
  kafkactl -C kafkactl.yaml --context direct create topic my-test-topic
expected:
  message: "topic created: my-test-topic"
  return_code: 0
render_output: false
{% endvalidation %}

Then produce a message through the virtual cluster:

{% validation custom-command %}
command: |
  kafkactl -C kafkactl.yaml --context vc produce my-test-topic --value="test message"
expected:
  message: "message produced (partition=0	offset=1)"
  return_code: 0
render_output: false
{% endvalidation %}

You should see the following responses:
```shell
topic created: my-test-topic
message produced (partition=0	offset=0)
```
{:.no-copy-code}

## View metrics in Prometheus

Now that we’ve configured the OTEL collector to scrape the metrics endpoint and send them to Prometheus, let’s look at what data is available in Prometheus. 
If we go to the query tab, we will see the metrics populated:

1. In your browser, open the Prometheus dashboard at `http://localhost:9090/`. 
1. Search for `kong` to see the list of available metrics.
1. Let's look at a sample metric: `kong_keg_kafka_backend_roundtrip_duration_seconds`. 
This tells you how it takes for the {{site.event_gateway_short}} to reach the backend cluster.

## View traces in Jaeger

Let's go to Jaeger to see we can see the full trace generated by {{site.event_gateway_short}}.

1. In your browser, open the Jaeger search dashboard at `http://localhost:16686/search`.
1. Search for `eventgw`.

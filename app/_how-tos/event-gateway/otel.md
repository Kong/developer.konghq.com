---
title: Set up observability for {{site.event_gateway}}
content_type: how_to
breadcrumbs:
  - /event-gateway/

products:
    - event-gateway

works_on:
    - konnect

tags:
    - observability
    - kafka
    - troubleshooting

description: ""

tldr: 
  q: How do I set see metrics and traces for {{site.event_gateway}}?
  a: |
    Export metrics and traces from {{site.event_gateway}} into your own observability systems using OpenTelemetry (OTEL), which helps you understand how {{site.event_gateway_short}} functions and how to troubleshoot it when something goes wrong.

    In this tutorial, we're using Jaeger and Prometheus, but you can substitute your own preferred tools as well.
tools:
    - konnect-api

# faqs:
#   - q: What metrics are available for {{site.event_gateway}}?
#     a: You can find the list of metrics somewhere
  
prereqs:
  skip_product: true
  inline:
    - title: Install kafkactl
      position: before
      content: |
        Install [kafkactl](https://github.com/deviceinsight/kafkactl?tab=readme-ov-file#installation). You'll need it to interact with Kafka clusters. 

    - title: Start a local Kafka cluster
      position: before
      include_content: knep/docker-compose-start

    - title: Create an {{site.event_gateway_short}} control plane
      include_content: knep/docker-compose-start

related_resources:
  - text: "{{site.event_gateway_short}} Control Plane API"
    url: /api/konnect/event-gateway/
  - text: Event Gateway
    url: /event-gateway/

---

In this guide, you'll configure:

* An [OpenTelemetry (OTEL) collector](https://opentelemetry.io/docs/collector/) to receive data from {{site.event_gateway_short}} and send it to the observability systems.
* [Jaeger](https://www.jaegertracing.io/) for visualizing traces from {{site.event_gateway_short}}.
* [Prometheus](https://prometheus.io/) for visualizing and querying metrics from {{site.event_gateway_short}}.

Here's how it works:

{% mermaid %}
flowchart LR

    A[Traces]
    B[Metrics]
    C[OTLP
    receiver]
    D[Prometheus
    receiver]
    E[Tracing system]
    F[Metrics system]

    subgraph id1 [Event Gateway]
    A
    B
    end

    A --push traces --> C
    B --scrape metrics--> D

    subgraph id2 [OTEL Collector]
    C
    D
    end

    C -- Export traces --> E
    D -- Export metrics --> F
{% endmermaid %}

In this setup:
1. {{site.event_gateway_short}} generates traces and metrics.
1. Using the OTEL collector:
  * The OTLP receiver gathers traces generated by {{site.event_gateway_short}}.
  * The Prometheus receiver ingests the Prometheus-compatible metrics directly from {{site.event_gateway_short}}.
1. We export the data to our Prometheus instance using the OTLP/HTTP exporter, which sends metrics directly to Prometheusâ€™ OTLP endpoint.


## Create an {{site.event_gateway_short}} data plane

First, let's launch an {{site.event_gateway_short}} data plane. 
Make sure that you already have an Event Gateway control plane; 
this example uses a control plane that we created in the [prerequisites](#prerequisites).

<!-- What's the best way to do this? We need to do add some config parameters here, but I don't know how to set those with the quickstart -->

Run the quickstart script to automatically provision a demo Kong Gateway control plane and data plane, and configure your environment:

```sh
curl -Ls https://get.konghq.com/event-gateway | bash -s -- \
  -k $KONNECT_TOKEN \
  -N kafka_event_gateway \
  -e "KEG__OBSERVABILITY__OTLP__TRACING__ENABLED=true" \
  -e "OTEL_EXPORTER_OTLP_PROTOCOL=grpc" \
  -e "OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317" \
  -e "OTEL_EXPORTER_OTLP_TIMEOUT=10s" \
  -e "OTEL_SERVICE_NAME=keg" \
  -p 8080:8080 \
  -p 19092-19095:19092-19095
```
This sets up an Kong Gateway control plane named `event-gateway-quickstart`, provisions a local data plane, and prints out the following environment variable export:

```
export EVENT_GATEWAY_ID=your-gateway-id
```
Copy and paste this into your terminal to configure your session.

As part of this launch, you also configured the following custom telemetry settings:

{% table %}
columns:
  - title: Parameter
    key: param
  - title: Default
    key: default
  - title: New value
    key: new
  - title: Description
    key: desc
rows:
  - param: "`KEG__OBSERVABILITY__OTLP__TRACING__ENABLED`"
    default: "`false`"
    new: "`true`"
    desc: Determines whether to turn on OTLP tracing.
  - param: "`KEG__RUNTIME__HEALTH_LISTENER_ADDRESS_PORT`"
    default: "`localhost:8080`"
    new: "`0.0.0.0:8080`"
    desc: Determines the address and port for the health listener where metrics are exposed for scraping.
  - param: "`OTEL_EXPORTER_OTLP_PROTOCOL`"
    default: "`http/protobuf`"
    new: "`grpc`"
    desc: Protocol used to export OpenTelemetry data.
  - param: "`OTEL_EXPORTER_OTLP_ENDPOINT`"
    default: "`https://localhost:4317`"
    new: "`http://otel-collector:4317`"
    desc: Endpoint to send OpenTelemetry data. In most cases, this will be an OTEL collector URL.
  - param: "`OTEL_EXPORTER_OTLP_TIMEOUT`"
    default: 10s
    new: 10s
    desc: Max waiting time for the backend to process each metrics batch. We're not adjusting this for the tutorial, but you can adjust as needed for troubleshooting.
  - param: "`OTEL_SERVICE_NAME`"
    default: none
    new: "`keg`"
    desc: Name of the OTEL service identified in the observability tools. For example, metrics in Prometheus will be prefixed with `kong_keg_*`.
{% endtable %}


## Configure the OTEL collector and Prometheus

Next, create two configuration files: one for the OTEL collector, and one for Prometheus.

Create an OTEL collector configuration file:

<!--vale off-->
{% validation custom-command %}
command: |
  cat <<EOF > otel-collector-config.yaml
  receivers:
    otlp/keg:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
    prometheus/keg:
      config:
        scrape_configs:
          - job_name: kong
            scrape_interval: 5s
            static_configs:
              - targets: ['kong_event_gateway:8080']

  processors:
    batch: {}

  extensions:
    health_check: {}

  exporters:
    otlp/jaeger:
      endpoint: jaeger:4317
      tls:
        insecure: true
    otlphttp/prometheus:
      endpoint: http://prometheus:9090/api/v1/otlp
      tls:
        insecure: true

  service:
    pipelines:
      traces:
        receivers: [otlp/keg]
        processors: [batch]
        exporters: [otlp/jaeger]
      metrics:
        receivers: [prometheus/keg]
        processors: [batch]
        exporters: [otlphttp/prometheus]
  EOF
expected:
  return_code: 0
render_output: false
{% endvalidation %}
<!--vale on-->

Create a Prometheus configuration file:

<!--vale off-->
{% validation custom-command %}
command: |
  cat <<EOF > prometheus.yaml
  global:
    scrape_interval: 5s

  scrape_configs:
    - job_name: 'prometheus'
      static_configs:
        - targets: ['localhost:9090']
  EOF
expected:
  return_code: 0
render_output: false
{% endvalidation %}
<!--vale on-->


## Launch OTEL collector stack

Launch the OTEL stack, making sure that it communicates on the same network as your Kafka cluster and your {{site.event_gateway_short}} data plane:

```yaml
cat <<EOF > docker-compose.yaml

name: otel-stack
networks:
  keg:
    external: true

services:
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    networks:
      - keg
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317"     # OTLP gRPC receiver

  jaeger:
    image: jaegertracing/all-in-one:latest
    networks:
      - keg
    ports:
      - "6831:6831/udp" # UDP port for Jaeger agent
      - "16686:16686"   # Web UI
      - "14268:14268"   # HTTP port for spans

  prometheus:
    image: prom/prometheus:latest
    networks:
      - keg
    command:
      - '--config.file=/etc/prometheus/prometheus.yaml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-otlp-receiver'   # Enables Prometheus to receive metrics using OTLP
    volumes:
      - ./prometheus.yaml:/etc/prometheus/prometheus.yaml
    ports:
      - "9090:9090"
EOF
```

```sh
docker compose up -d
```

## Add Kafka configuration

Use the following Kafka configuration to access your Kafka resources from the virtual clusters:

<!--vale off-->
{% validation custom-command %}
command: |
  cat <<EOF > kafkactl.yaml
  contexts:
    direct:
      brokers:
        - localhost:9095
        - localhost:9096
        - localhost:9094
    vc:
      brokers:
        - localhost:19092
  EOF
expected:
  return_code: 0
render_output: false
{% endvalidation %}
<!--vale on-->

## Create entities

* backend cluster, listener, virtual cluster - can we shortcut this somehow?

## Validate
---
title: Set up observability for {{site.event_gateway}}
content_type: how_to
permalink: /event-gateway/configure-observability-with-otel/
breadcrumbs:
  - /event-gateway/

products:
    - event-gateway

works_on:
    - konnect

tags:
    - observability
    - kafka
    - troubleshooting

description: "Export metrics and traces from {{site.event_gateway}} into your own observability systems using OpenTelemetry (OTEL)."

tldr: 
  q: How do I set see metrics and traces for {{site.event_gateway}}?
  a: |
    Export metrics and traces from {{site.event_gateway}} into your own observability systems using OpenTelemetry (OTEL), which helps you understand how {{site.event_gateway_short}} functions and how to troubleshoot it when something goes wrong.

    In this tutorial, we're using Jaeger and Prometheus, but you can substitute your own preferred tools as well.
tools:
    - konnect-api

faqs:
  - q: What metrics are available for {{site.event_gateway}}?
    a: You can find the list of all available metrics in the [metrics reference](/event-gateway/metrics/).
  
prereqs:
  skip_product: true
  inline:
    - title: Install kafkactl
      position: before
      content: |
        Install [kafkactl](https://github.com/deviceinsight/kafkactl?tab=readme-ov-file#installation). You'll need it to interact with Kafka clusters. 

    - title: Start a local Kafka cluster
      position: before
      include_content: knep/docker-compose-start

related_resources:
  - text: "{{site.event_gateway_short}} Control Plane API"
    url: /api/konnect/event-gateway/
  - text: Event Gateway metrics reference
    url: /event-gateway/metrics/

automated_tests: false

---

In this guide, you'll configure:

* An [OpenTelemetry (OTEL) collector](https://opentelemetry.io/docs/collector/) to receive data from {{site.event_gateway_short}} and send it to the observability systems.
* [Jaeger](https://www.jaegertracing.io/) for visualizing traces from {{site.event_gateway_short}}.
* [Prometheus](https://prometheus.io/) for visualizing and querying metrics from {{site.event_gateway_short}}.

Here's how it works:

{% mermaid %}
flowchart LR

    A[Traces]
    B[Metrics]
    C[OTLP
    receiver]
    D[Prometheus
    receiver]
    E[Tracing system]
    F[Metrics system]

    subgraph id1 [Event Gateway]
    A
    B
    end

    A --push traces --> C
    B --scrape metrics--> D

    subgraph id2 [OTEL Collector]
    C
    D
    end

    C -- Export traces --> E
    D -- Export metrics --> F
{% endmermaid %}

In this setup:
1. {{site.event_gateway_short}} generates traces and metrics.
1. Using the OTEL collector:
  * The OTLP receiver gathers traces generated by {{site.event_gateway_short}}.
  * The Prometheus receiver ingests the Prometheus-compatible metrics directly from {{site.event_gateway_short}}.
1. We export the data to our Prometheus instance using the OTLP/HTTP exporter, which sends metrics directly to Prometheus’ OTLP endpoint.

## Create an {{site.event_gateway_short}} control plane and data plane

Run the quickstart script to automatically provision a demo {{site.event_gateway_short}} control plane and data plane, and configure your environment for sending metrics and traces:

```sh
curl -Ls https://get.konghq.com/event-gateway | bash -s -- \
  -k $KONNECT_TOKEN \
  -N kafka_event_gateway \
  -e "KEG__OBSERVABILITY__OTLP__TRACING__ENABLED=true" \
  -e "KEG__RUNTIME__HEALTH_LISTENER_ADDRESS_PORT=0.0.0.0:8080" \
  -e "OTEL_EXPORTER_OTLP_PROTOCOL=grpc" \
  -e "OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317" \
  -e "OTEL_EXPORTER_OTLP_TIMEOUT=10s" \
  -e "OTEL_SERVICE_NAME=eventgw"
```

Where you configure the following custom telemetry settings:

{% table %}
columns:
  - title: Parameter
    key: param
  - title: Default
    key: default
  - title: New value
    key: new
  - title: Description
    key: desc
rows:
  - param: "`KEG__OBSERVABILITY__OTLP__TRACING__ENABLED`"
    default: "`false`"
    new: "`true`"
    desc: Determines whether to turn on OTLP tracing.
  - param: "`KEG__RUNTIME__HEALTH_LISTENER_ADDRESS_PORT`"
    default: "`localhost:8080`"
    new: "`0.0.0.0:8080`"
    desc: Determines the address and port for the health listener where metrics are exposed for scraping.
  - param: "`OTEL_EXPORTER_OTLP_PROTOCOL`"
    default: "`http/protobuf`"
    new: "`grpc`"
    desc: Protocol used to export OpenTelemetry data.
  - param: "`OTEL_EXPORTER_OTLP_ENDPOINT`"
    default: "`https://localhost:4317`"
    new: "`http://otel-collector:4317`"
    desc: Endpoint to send OpenTelemetry data. In most cases, this will be an OTEL collector URL.
  - param: "`OTEL_EXPORTER_OTLP_TIMEOUT`"
    default: 10s
    new: 10s
    desc: Max waiting time for the backend to process each metrics batch. We're not adjusting this for the tutorial, but you can adjust as needed for troubleshooting.
  - param: "`OTEL_SERVICE_NAME`"
    default: none
    new: "`eventgw`"
    desc: Name of the OTEL service identified in the observability tools. For example, in Jaeger, the service will appear as `eventgw`.
{% endtable %}

This sets up an {{site.event_gateway_short}} control plane named `event-gateway-quickstart`, provisions a local data plane, and prints out the following environment variable export:

```
export EVENT_GATEWAY_ID=your-gateway-id
```

Copy and paste this into your terminal to configure your session.

{% include_cached /knep/quickstart-note.md %}

## Configure the OTEL collector and Prometheus

Next, we need to create two configuration files: one for the OTEL collector, and one for Prometheus.

Open a new terminal window and create a directory for the configuration:
```sh
mkdir otel && cd otel
```

Create an OTEL collector configuration file:

<!--vale off-->
{% validation custom-command %}
command: |
  cat <<EOF > otel-collector-config.yaml
  receivers:
    otlp/keg:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
    prometheus/keg:
      config:
        scrape_configs:
          - job_name: kong
            scrape_interval: 5s
            static_configs:
              - targets: ['event-gateway-quickstart:8080']

  processors:
    batch: {}

  extensions:
    health_check: {}

  exporters:
    otlp/jaeger:
      endpoint: jaeger:4317
      tls:
        insecure: true
    otlphttp/prometheus:
      endpoint: http://prometheus:9090/api/v1/otlp
      tls:
        insecure: true

  service:
    pipelines:
      traces:
        receivers: [otlp/keg]
        processors: [batch]
        exporters: [otlp/jaeger]
      metrics:
        receivers: [prometheus/keg]
        processors: [batch]
        exporters: [otlphttp/prometheus]
  EOF
expected:
  return_code: 0
render_output: false
{% endvalidation %}
<!--vale on-->

Create a Prometheus configuration file:

<!--vale off-->
{% validation custom-command %}
command: |
  cat <<EOF > prometheus.yaml
  global:
    scrape_interval: 5s

  scrape_configs:
    - job_name: 'prometheus'
      static_configs:
        - targets: ['localhost:9090']
  EOF
expected:
  return_code: 0
render_output: false
{% endvalidation %}
<!--vale on-->

## Launch OTEL collector stack

Now, let's run the OTEL collector stack with Jaeger and Prometheus.

Run the following command to save a Docker compose file, making sure that it communicates on the same network as your Kafka cluster and your {{site.event_gateway_short}} data plane:
```yaml
cat <<EOF > docker-compose.yaml

name: otel-stack
networks:
  kafka:
    name: kafka_event_gateway
    external: true

services:
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    networks:
      - kafka
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317"  # OTLP gRPC receiver
      - "18639:9090" # Use this for testing the scraping endpoint
  
  jaeger:
    image: jaegertracing/all-in-one:latest
    networks:
      - kafka
    ports:
      - "6831:6831/udp" # UDP port for Jaeger agent
      - "16686:16686"   # Web UI
      - "14268:14268"   # HTTP port for spans

  prometheus:
    image: prom/prometheus:latest
    networks:
      - kafka
    command:
      - '--config.file=/etc/prometheus/prometheus.yaml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-otlp-receiver'   # Enables Prometheus to receive metrics using OTLP
    volumes:
      - ./prometheus.yaml:/etc/prometheus/prometheus.yaml
    ports:
      - "9090:9090"
EOF
```

Launch the OTEL stack:
```sh
docker compose up -d
```

## Add Kafka configuration

Use the following Kafka configuration to access your Kafka resources from the virtual clusters:

<!--vale off-->
{% validation custom-command %}
command: |
  cat <<EOF > kafkactl.yaml
  contexts:
    direct:
      brokers:
        - localhost:9095
        - localhost:9096
        - localhost:9094
    vc:
      brokers:
        - localhost:19092
  EOF
expected:
  return_code: 0
render_output: false
{% endvalidation %}
<!--vale on-->

## Create a backend cluster

Use the following command to create a [backend cluster](/event-gateway/entities/backend-cluster/) that connects to the Kafka servers you set up:

<!--vale off-->
{% konnect_api_request %}
url: /v1/event-gateways/$EVENT_GATEWAY_ID/backend-clusters
status_code: 201
method: POST
body:
  name: backend_cluster
  bootstrap_servers:
    - kafka1:9092
    - kafka2:9092
    - kafka3:9092
  authentication:
    type: anonymous
  tls:
    enabled: false
  insecure_allow_anonymous_virtual_cluster_auth: true
extract_body:
  - name: id
    variable: BACKEND_CLUSTER_ID
capture: BACKEND_CLUSTER_ID
jq: ".id"
{% endkonnect_api_request %}
<!--vale on-->

In this example configuration:
* `bootstrap_servers`: Points the backend cluster to the three bootstrap servers that we launched in the prerequisites. 
* `authentication` and `insecure_allow_anonymous_virtual_cluster_auth`: For demo purposes, we're allowing insecure `anonymous` connections, which means no authentication required. 
* `tls`: TLS is disabled so that we can easily test the connection.

## Add a virtual cluster

Run the following command to create a new [virtual cluster](/event-gateway/entities/virtual-cluster/) associated with our backend cluster. This will let you route event traffic and apply policies:

<!--vale off-->
{% konnect_api_request %}
url: /v1/event-gateways/$EVENT_GATEWAY_ID/virtual-clusters
status_code: 201
method: POST
body:
  name: example_virtual_cluster
  destination:
    id: $BACKEND_CLUSTER_ID
  dns_label: vcluster-1
  authentication:
    - type: anonymous
  acl_mode: passthrough
extract_body:
  - name: id
    variable: VIRTUAL_CLUSTER_ID
capture: VIRTUAL_CLUSTER_ID
jq: ".id"
{% endkonnect_api_request %}
<!--vale on-->

In this example:
* `authentication`: Allows anonymous authentication.
* `acl_mode`: The setting `passthrough` means that all clients are allowed and don't have to match a defined ACL. 
In a production environment, you would set this to `enforce_on_gateway` and define an ACL policy.
* `name` is an internal name for the configuration object, while the `dns_label` is necessary for SNI routing.

## Add a listener and policy

For testing purposes, we'll use **port forwarding** to route traffic to the virtual cluster.  
In production environments, you should use **SNI routing** instead.

Run the following command to create a new [listener](/event-gateway/entities/listener/):
<!--vale off-->
{% konnect_api_request %}
url: /v1/event-gateways/$EVENT_GATEWAY_ID/listeners
status_code: 201
method: POST
body:
  name: example_listener
  addresses:
    - 0.0.0.0
  ports:
    - 19092-19095
extract_body:
  - name: id
    variable: LISTENER_ID
capture: LISTENER_ID
jq: ".id"
{% endkonnect_api_request %}
<!--vale on-->

Create the [port mapping policy](/event-gateway/policies/forward-to-virtual-cluster/):

<!--vale off-->
{% konnect_api_request %}
url: /v1/event-gateways/$EVENT_GATEWAY_ID/listeners/$LISTENER_ID/policies
status_code: 201
method: POST
body:
  type: forward_to_virtual_cluster
  name: forward
  config:
    type: port_mapping
    advertised_host: localhost
    destination: 
      id: $VIRTUAL_CLUSTER_ID
{% endkonnect_api_request %}
<!--vale on-->

## Validate the cluster

Create a topic using the `direct` context, which is a direct connection to our Kafka cluster:

{% validation custom-command %}
command: |
  kafkactl -C kafkactl.yaml --context direct create topic my-test-topic
expected:
  message: "topic created: my-test-topic"
  return_code: 0
render_output: false
{% endvalidation %}

Then produce a message through the virtual cluster:

{% validation custom-command %}
command: |
  kafkactl -C kafkactl.yaml --context vc produce my-test-topic --value="test message"
expected:
  message: "message produced (partition=0	offset=1)"
  return_code: 0
render_output: false
{% endvalidation %}

You should see the following responses:
```shell
topic created: my-test-topic
message produced (partition=0	offset=0)
```
{:.no-copy-code}

## View metrics in Prometheus

Now that we’ve configured the OTEL collector to scrape the metrics endpoint and send them to Prometheus, let’s look at what data is available in Prometheus. 
If we go to the query tab, we will see the metrics populated:

1. In your browser, open the Prometheus dashboard at `http://localhost:9090/`. 
1. Search for `kong` to see the list of available metrics.
1. Let's look at a sample metric: `kong_keg_kafka_backend_roundtrip_duration_seconds_sum`.

This tells you how long it took for the {{site.event_gateway_short}} to send a request to the backend cluster and receive a response.

## View traces in Jaeger

Let's go to Jaeger to see we can see the full trace generated by {{site.event_gateway_short}}.

1. Send any command through the virtual cluster, such as `list topics`:

   ```sh
   kafkactl -C kafkactl.yaml --context vc list topics
   ```
1. In your browser, open the Jaeger search dashboard at `http://localhost:16686/search`.
1. Select the `eventgw` service.
1. Click **Find Traces**.

Here you can see the full trace generated by {{site.event_gateway_short}} for each command.
For example, you can click an `eventgw: request` trace to see the details, including information about the virtual cluster and backend cluster.


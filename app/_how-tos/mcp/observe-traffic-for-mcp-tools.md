---
title: Observe MCP traffic for autogenerated MCP tools
content_type: how_to
related_resources:
  - text: "{{site.ai_gateway}}"
    url: /ai-gateway/
  - text: AI MCP Proxy
    url: /plugins/ai-mcp-proxy/
  - text: Prometheus plugin
    url: /plugins/prometheus/
  - text: A trust and control layer for proxying traffic to MCP servers
    url: /mcp/

description: Learn how to monitor traffic for autogenerated MCP tools using the AI MCP Proxy plugin and Prometheus, so you can track tool usage and latency.

products:
  - gateway
  - ai-gateway

permalink: /mcp/observe-traffic-for-mcp-tools/

series:
  id: mcp-conversion
  position: 2

works_on:
  - on-prem
  - konnect

min_version:
  gateway: '3.12'

plugins:
  - ai-mcp-proxy
  - prometheus

entities:
  - service
  - route
  - plugin

tags:
  - ai
  - openai
  - mcp
  - serverless

tldr:
  q: How do I monitor autogenerated MCP tool traffic?
  a: |
    Reconfigure the AI MCP Proxy plugin to enable logging of payloads and statistics for your MCP tools, then enable the Prometheus plugin to scrape and collect these metrics for monitoring.

tools:
  - deck

cleanup:
  inline:
    - title: Prometheus
      content: |
        Once you are done experimenting with Prometheus, you can use the following
        commands to stop the Prometheus server you created in this guide:

        ```sh
        docker stop kong-quickstart-prometheus
        ```
      icon_url: /assets/icons/third-party/prometheus.svg
    - title: Destroy the {{site.base_gateway}} container
      include_content: cleanup/products/gateway
      icon_url: /assets/icons/gateway.svg
    - title: Clean up {{site.konnect_short_name}} environment
      include_content: cleanup/platform/konnect
      icon_url: /assets/icons/gateway.svg

automated_tests: false
---

## Reconfigure the AI MCP Proxy plugin

To observe traffic for MCP tools, you first must **enable logging and statistics** on the AI MCP Proxy plugin. Apply the below configuration for the AI MCP Proxy plugin with enabled logging capabilities:

{% entity_examples %}
entities:
  plugins:
    - name: ai-mcp-proxy
      route: mcp-route
      config:
        logging:
          log_payloads: true
          log_statistics: true
        mode: conversion-listener
        tools:
        - description: Get users
          method: GET
          path: "/marketplace/users"
          parameters:
          - name: id
            in: query
            required: false
            schema:
              type: string
            description: Optional user ID
        - description: Get orders for a user
          method: GET
          path: "/marketplace/orders"
          parameters:
          - description: User ID to filter orders
            in: query
            name: userid
            required: true
            schema:
              type: string
        server:
          timeout: 60000
{% endentity_examples %}

## Enable the Prometheus plugin

Before you configure Prometheus, enable the [Prometheus plugin](/plugins/prometheus/) on {{site.base_gateway}}:

{% entity_examples %}
entities:
  plugins:
    - name: prometheus
      route: mcp-route
      config:
        status_code_metrics: true
        ai_metrics: true
{% endentity_examples %}

## Configure Prometheus

Create a `prometheus.yml` file:

```sh
touch prometheus.yml
```

Now, add the following to the `prometheus.yml` file to configure Prometheus to scrape MCP traffic metrics:


```yaml
cat <<EOF > prometheus.yml
scrape_configs:
 - job_name: 'kong'
   scrape_interval: 5s
   static_configs:
     - targets: ['kong-quickstart-gateway:8001']
EOF
```
{: data-deployment-topology="on-prem" }

```yaml
cat <<EOF > prometheus.yml
scrape_configs:
 - job_name: 'kong'
   scrape_interval: 5s
   static_configs:
     - targets: ['kong-quickstart-gateway:8100']
EOF
```
{: data-deployment-topology="konnect" }


Run a Prometheus server, and pass it the configuration file created in the previous step:

```sh
docker run -d --name kong-quickstart-prometheus \
  --network=kong-quickstart-net -p 9090:9090 \
  -v $(PWD)/prometheus.yml:/etc/prometheus/prometheus.yml \
  prom/prometheus:latest
```

Prometheus will begin to scrape metrics data from {{site.base_gateway}}.

## Validate the configuration

You can validate that the Prometheus plugin is collecting metrics by generating MCP traffic to the `mcp-service`. Enter the following question in the Cursor chat:

```text
What users do you see in the API?
```

Once Cursor agent has finished reasoning, run the following to query the collected `kong_ai_mcp_latency_ms` metric data:

```
curl -s 'localhost:9090/api/v1/query?query=kong_ai_mcp_latency_ms_bucket'
```

This should return something like the following:

```json
{
  "status": "success",
  "data": {
    "resultType": "vector",
    "result": [
      {
        "metric": {
          "__name__": "kong_ai_mcp_latency_ms_bucket",
          "instance": "kong-quickstart-gateway:8001",
          "job": "kong",
          "le": "25.0",
          "method": "tools/call",
          "route": "mcp-route",
          "service": "mcp-service",
          "tool_name": "mcp-route-1",
          "workspace": "default"
        },
        "value": [1755759385.507, "3"]
      },
      {
        "metric": {
          "__name__": "kong_ai_mcp_latency_ms_bucket",
          "instance": "kong-quickstart-gateway:8001",
          "job": "kong",
          "le": "25.0",
          "method": "tools/call",
          "route": "mcp-route",
          "service": "mcp-service",
          "tool_name": "mcp-route-2",
          "workspace": "default"
        },
        "value": [1755759385.507, "2"],
      "..."
    ]
  }
}
```
